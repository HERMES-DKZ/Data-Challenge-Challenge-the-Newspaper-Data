{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Deutsche Digitale Bibliothek REST API: https://labs.deutsche-digitale-bibliothek.de/app/ddbapi/#/search/getSolrSearch\n",
    "\n",
    "Fragen & Antworten zum Deutschen Zeitungsportal: https://www.deutsche-digitale-bibliothek.de/content/newspaper/fragen-antworten\n",
    "\n",
    "Wrapper for the DDB API: https://pypi.org/project/ddbapi/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for extracting and analyzing data from Das Deutsche Zeitungsportal: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ddbapi import zp_pages\n",
    "import folium\n",
    "from geopy import geocoders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def article_extractor(search_dict):\n",
    "    \"\"\"\n",
    "    This function extracts newspaper articles in a given language between two given dates. It takes a dictionary with \n",
    "    three keys as its only argument, like the following example:\n",
    "\n",
    "    search_dict= {\n",
    "        'language': 'ger',\n",
    "        'date_begin': f'{year}-01-01',\n",
    "        'date_end': f'{year}-12-31'\n",
    "        }\n",
    "    \"\"\"\n",
    "    \n",
    "    df= zp_pages(language=search_dict['language'], \n",
    "                  publication_date= f\"[{search_dict['date_begin']}T12:00:00Z TO {search_dict['date_end']}T12:00:00Z]\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year= 1990\n",
    "path= \"./data_deutsches_zeitungsportal_misc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_dict= {\n",
    "     'language': 'ger',\n",
    "     'date_begin': f'{year}-01-01',\n",
    "     'date_end': f'{year}-04-30'\n",
    "     }\n",
    "    \n",
    "df_challenge= article_extractor(search_dict)\n",
    "df_challenge.to_pickle(f\"{path}/newspapers_{search_dict['language']}_{year}_part_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_dict= {\n",
    "     'language': 'ger',\n",
    "     'date_begin': f'{year}-05-01',\n",
    "     'date_end': f'{year}-08-31'\n",
    "     }\n",
    "    \n",
    "df_challenge= article_extractor(search_dict)\n",
    "df_challenge.to_pickle(f\"{path}/newspapers_{search_dict['language']}_{year}_part_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_dict= {\n",
    "     'language': 'ger',\n",
    "     'date_begin': f'{year}-09-01',\n",
    "     'date_end': f'{year}-12-31'\n",
    "     }\n",
    "    \n",
    "df_challenge_ger= article_extractor(search_dict)\n",
    "df_challenge_ger.to_pickle(f\"{path}/newspapers_{search_dict['language']}_{year}_part_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # testing if the pickled dataframes are loadable: \n",
    "\n",
    "test_year= f\"{year}_part_3\"\n",
    "columns= ['paper_title', 'publication_date', 'place_of_distribution']\n",
    "try:\n",
    "     print (len(pd.read_pickle(f\"{path}/newspapers_{search_dict['language']}_{test_year}\")[columns]))\n",
    "                  \n",
    "except EOFError:\n",
    "     print(f\"Error: EOFError occurred while loading data for year {test_year}.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
